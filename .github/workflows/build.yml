---
name: Build Bazzite AI
on:
  push:
    branches:
      - main
  merge_group:
  pull_request:
  workflow_dispatch:

env:
  IMAGE_NAME: "${{ github.event.repository.name }}" # the name of the image produced by this build, matches repo names
  IMAGE_DESC: "${{ github.event.repository.description }}"
  IMAGE_REGISTRY: "ghcr.io/${{ github.repository_owner }}" # do not edit
  ARTIFACTHUB_LOGO_URL: "https://avatars.githubusercontent.com/u/187439889?s=200&v=4"

  # The tag used in the image from which we base of.
  # ex.: ghcr.io/org/image:IMAGE_SOURCE_TAG
  IMAGE_SOURCE_TAG: "latest"
  SOURCE_ORG: "ublue-os"
  SOURCE_REPO: "bazzite"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref || github.run_id }}-${{ inputs.brand_name}}-${{ inputs.stream_name }}
  cancel-in-progress: true

jobs:
  build_push:
    name: Build and push image
    runs-on: ubuntu-24.04

    env:
      BASE_IMAGE: bazzite-nvidia-open

    permissions:
      contents: read
      packages: write
      id-token: write

    steps:
      # These stage versions are pinned by https://github.com/renovatebot/renovate
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

      # # This is optional, but if you see that your builds are way too big for the runners, you can enable this by uncommenting the following lines:
      # - name: Maximize build space
      #   uses: ublue-os/remove-unwanted-software@cc0becac701cf642c8f0a6613bbdaf5dc36b259e # v9
      #   with:
      #     remove-codeql: true

      - name: Mount BTRFS for podman storage
        uses: ublue-os/container-storage-action@main

      # Persistent DNF5 cache shared across all builds
      # Significantly speeds up package downloads by caching RPM packages
      - name: Cache DNF5 packages
        uses: actions/cache@v4
        id: dnf-cache
        with:
          path: /tmp/dnf-cache
          key: ${{ runner.os }}-dnf5-os-${{ hashFiles('build_files/20-install-apps.sh', 'Containerfile') }}-${{ hashFiles('build_files/**/*.sh') }}
          restore-keys: |
            ${{ runner.os }}-dnf5-os-${{ hashFiles('build_files/20-install-apps.sh', 'Containerfile') }}-
            ${{ runner.os }}-dnf5-os-
            ${{ runner.os }}-dnf5-containers-
            ${{ runner.os }}-dnf5-

      # Set up DNF cache directory for buildah to use
      - name: Set up DNF cache directory
        run: |
          sudo mkdir -p /var/cache/dnf5
          sudo chown -R $(id -u):$(id -g) /var/cache/dnf5
          # Restore from GitHub Actions cache if it exists
          if [ -d "/tmp/dnf-cache/dnf5" ]; then
            echo "Restoring DNF cache from /tmp/dnf-cache/dnf5 to /var/cache/dnf5"
            sudo cp -rp /tmp/dnf-cache/dnf5/* /var/cache/dnf5/ || true
            echo "Cache size: $(du -sh /var/cache/dnf5 | cut -f1)"
          else
            echo "No existing cache found, starting fresh"
          fi

      # Pre-pull and cache base images for faster builds in parallel
      - name: Pull and cache base images
        run: |
          mkdir -p ~/.local/share/containers/storage
          # Pull base image for OS build in background for parallelization
          buildah pull ghcr.io/${{ env.SOURCE_ORG }}/${{ env.BASE_IMAGE }}:${{ env.IMAGE_SOURCE_TAG || 'latest' }} || true &
          # Wait for all pulls to complete
          wait
          echo "✓ Base images pulled and cached"

      - name: Get current date
        id: date
        run: |
          # This generates a timestamp like what is defined on the ArtifactHub documentation
          # E.G: 2022-02-08T15:38:15Z'
          # https://artifacthub.io/docs/topics/repositories/container-images/
          # https://linux.die.net/man/1/date
          echo "date=$(date -u +%Y\-%m\-%d\T%H\:%M\:%S\Z)" >> $GITHUB_OUTPUT

      # OUTPUTS:
      #   - SOURCE_VERSION: version of the source image. Ex.: testing-41.20250312
      #   - SOURCE_VERSION_MAJOR: major version. Used to identify big releases. Ex.: 41
      - name: Get image major version
        id: fetch_source_meta
        env:
          org: ${{ env.SOURCE_ORG }}
          IMAGE_SOURCE_TAG: ${{ env.IMAGE_SOURCE_TAG || 'latest' }}
        run: |
          set -x
          # SOURCE_VERSION_MAJOR must be a number
          declare -i SOURCE_VERSION_MAJOR=0

          # There are some ways to get the major release from an image.
          # First method: `skopeo inspect` and annotations.

          SOURCE_VERSION=$(
                skopeo inspect --no-tags --raw --config \
                "docker://ghcr.io/${org}/${BASE_IMAGE}:${IMAGE_SOURCE_TAG}" | \
                jq -r '.config.Labels["org.opencontainers.image.version"]'
          )
          if [[ -z $SOURCE_VERSION ]]; then
            echo "::error::$SOURCE_VERSION was not fetched correctly: $SOURCE_VERSION=${$SOURCE_VERSION}"
            exit 1
          fi
          echo "SOURCE_VERSION=$SOURCE_VERSION" >>$GITHUB_OUTPUT

          SOURCE_VERSION_MAJOR=$([[ ${SOURCE_VERSION} =~ ^(.*-)?([[:digit:]]+) ]] && echo "${BASH_REMATCH[-1]}")
          _status=$?
          unset -v _tag

          if [[ $_status -ne 0 ]] || [[ -z ${SOURCE_VERSION_MAJOR} ]] || (( SOURCE_VERSION_MAJOR <= 0 )); then
            echo "::error::SOURCE_VERSION_MAJOR was not fetched correctly: SOURCE_VERSION_MAJOR=${SOURCE_VERSION_MAJOR}"
            exit 1
          fi

          echo "SOURCE_VERSION_MAJOR=$SOURCE_VERSION_MAJOR" >>$GITHUB_OUTPUT

      - name: Set output image name
        id: gen_image_ref
        run: |
          # Unified image name for all builds
          IMAGE_NAME="bazzite-ai"
          echo "IMAGE_NAME=${IMAGE_NAME}" | tee -a "$GITHUB_ENV"

      # Image metadata for https://artifacthub.io/ - This is optional but is highly recommended so we all can get a index of all the custom images
      # The metadata by itself is not going to do anything, you choose if you want your image to be on ArtifactHub or not.
      - name: Image Metadata
        uses: docker/metadata-action@902fa8ec7d6ecbf8d84d538b9b233a880e428804 # v5
        id: metadata
        with:
          # This generates all the tags for your image, you can add custom tags here too!
          # By default, it should generate "latest" and "latest.(date here)".
          tags: |
            type=raw,value=latest
            type=raw,value=stable
            type=raw,value=stable-${{ steps.fetch_source_meta.outputs.SOURCE_VERSION_MAJOR }}
            type=raw,value=stable-${{ steps.fetch_source_meta.outputs.SOURCE_VERSION_MAJOR }}.{{date 'YYYYMMDD'}}
            type=raw,value=${{ steps.fetch_source_meta.outputs.SOURCE_VERSION_MAJOR }}
            type=raw,value=${{ steps.fetch_source_meta.outputs.SOURCE_VERSION_MAJOR }}.{{date 'YYYYMMDD'}}
            type=sha,enable=${{ github.event_name == 'pull_request' }}
            type=ref,event=pr
          labels: |
            io.artifacthub.package.readme-url=https://raw.githubusercontent.com/${{ github.repository_owner }}/${{ env.IMAGE_NAME }}/refs/heads/main/README.md
            org.opencontainers.image.created=${{ steps.date.outputs.date }}
            org.opencontainers.image.description=${{ env.IMAGE_DESC }}
            org.opencontainers.image.documentation=https://raw.githubusercontent.com/${{ github.repository_owner }}/${{ env.IMAGE_NAME }}/refs/heads/main/README.md
            org.opencontainers.image.source=https://github.com/${{ github.repository_owner }}/${{ env.IMAGE_NAME }}/blob/main/Containerfile
            org.opencontainers.image.title=${{ env.IMAGE_NAME }}
            org.opencontainers.image.url=https://github.com/${{ github.repository_owner }}/${{ env.IMAGE_NAME }}
            org.opencontainers.image.vendor=${{ github.repository_owner }}
            org.opencontainers.image.version=${{ steps.fetch_source_meta.outputs.SOURCE_VERSION }}
            io.artifacthub.package.deprecated=false
            io.artifacthub.package.keywords=bootc,ublue,universal-blue
            io.artifacthub.package.license=Apache-2.0
            io.artifacthub.package.logo-url=${{ env.ARTIFACTHUB_LOGO_URL }}
            io.artifacthub.package.prerelease=false
            containers.bootc=1
          sep-tags: " "
          sep-annotations: " "

      # Unified buildah cache with hierarchical restore keys
      # Allows sharing layers across OS and container builds for maximum efficiency
      - name: Restore buildah cache tarball
        uses: actions/cache/restore@v4
        id: buildah-cache
        with:
          path: /tmp/buildah-cache-staging/buildah-cache.tar.gz
          key: ${{ runner.os }}-buildah-os-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildah-os-
            ${{ runner.os }}-buildah-containers-
            ${{ runner.os }}-buildah-

      # Extract buildah cache if it was restored
      - name: Extract buildah cache
        if: steps.buildah-cache.outputs.cache-hit == 'true'
        run: |
          echo "Extracting buildah cache from tarball"
          mkdir -p ~/.local/share/containers
          sudo tar -xzf /tmp/buildah-cache-staging/buildah-cache.tar.gz -C ~/.local/share/containers 2>/dev/null || true
          sudo chown -R $(id -u):$(id -g) ~/.local/share/containers
          echo "✓ Buildah cache restored"

      - name: Build Image
        id: build_image
        uses: redhat-actions/buildah-build@7a95fa7ee0f02d552a32753e7414641a04307056 # v2.13
        with:
          containerfiles: |
            ./Containerfile
          # Postfix image name with -custom to make it a little more descriptive
          # Syntax: https://docs.github.com/en/actions/learn-github-actions/expressions#format
          image: ${{ env.IMAGE_NAME }}
          tags: ${{ steps.metadata.outputs.tags }}
          labels: ${{ steps.metadata.outputs.labels }}
          oci: false
          build-args: |
            BASE_IMAGE=ghcr.io/${{ env.SOURCE_ORG }}/${{ env.BASE_IMAGE }}:${{ env.IMAGE_SOURCE_TAG || 'latest' }}
            IMAGE_NAME=${{ env.IMAGE_NAME }}
            IMAGE_VENDOR=${{ github.repository_owner }}
          # Mount DNF cache directory to speed up package downloads
          extra-args: |
            --volume /var/cache/dnf5:/var/cache/dnf5:z

      # Save DNF cache back to GitHub Actions cache location
      - name: Save DNF cache
        if: always()
        run: |
          echo "Saving DNF cache from /var/cache/dnf5 to /tmp/dnf-cache"
          mkdir -p /tmp/dnf-cache
          sudo cp -rp /var/cache/dnf5 /tmp/dnf-cache/ || true
          echo "Cache size: $(du -sh /tmp/dnf-cache | cut -f1)"

      # Manually save buildah cache with sudo to avoid permission errors
      # The standard actions/cache fails on setuid/shadow files
      - name: Save buildah cache manually
        if: always()
        run: |
          echo "Saving buildah cache manually with sudo"
          mkdir -p /tmp/buildah-cache-staging
          sudo tar -czf /tmp/buildah-cache-staging/buildah-cache.tar.gz -C ~/.local/share/containers . 2>/dev/null || true
          sudo chown $(id -u):$(id -g) /tmp/buildah-cache-staging/buildah-cache.tar.gz
          echo "Buildah cache size: $(du -sh /tmp/buildah-cache-staging/buildah-cache.tar.gz | cut -f1)"

      # Cache the buildah tarball (avoids permission issues)
      - name: Cache buildah tarball
        uses: actions/cache/save@v4
        if: always()
        with:
          path: /tmp/buildah-cache-staging/buildah-cache.tar.gz
          key: ${{ runner.os }}-buildah-os-${{ github.sha }}

      # Rechunk is a script that we use on Universal Blue to make sure there isnt a single huge layer when your image gets published.
      # This does not make your image faster to download, just provides better resumability and fixes a few errors.
      # Documentation for Rechunk is provided on their github repository at https://github.com/hhd-dev/rechunk
      # You can enable it by uncommenting the following lines:
      # - name: Run Rechunker
      #   id: rechunk
      #   uses: hhd-dev/rechunk@f153348d8100c1f504dec435460a0d7baf11a9d2 # v1.1.1
      #   with:
      #     rechunk: 'ghcr.io/hhd-dev/rechunk:v1.0.1'
      #     ref: "localhost/${{ env.IMAGE_NAME }}:${{ env.DEFAULT_TAG }}"
      #     prev-ref: "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.DEFAULT_TAG }}"
      #     skip_compression: true
      #     version: ${{ env.CENTOS_VERSION }}
      #     labels: ${{ steps.metadata.outputs.labels }} # Rechunk strips out all the labels during build, this needs to be reapplied here with newline separator

      # This is necessary so that the podman socket can find the rechunked image on its storage
      # - name: Load in podman and tag
      #   run: |
      #     IMAGE=$(podman pull ${{ steps.rechunk.outputs.ref }})
      #     sudo rm -rf ${{ steps.rechunk.outputs.output }}
      #     for tag in ${{ steps.metadata.outputs.tags }}; do
      #       podman tag $IMAGE ${{ env.IMAGE_NAME }}:$tag
      #     done

      # These `if` statements are so that pull requests for your custom images do not make it publish any packages under your name without you knowing
      # They also check if the runner is on the default branch so that things like the merge queue (if you enable it), are going to work
      - name: Login to GitHub Container Registry
        uses: docker/login-action@74a5d142397b4f367a81961eba4e8cd7edddf772 # v3
        if: github.event_name != 'pull_request'
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Workaround bug where capital letters in your GitHub username make it impossible to push to GHCR.
      # https://github.com/macbre/push-to-ghcr/issues/12
      - name: Lowercase Image and Registry
        id: lowercase
        env:
          IMAGE_REGISTRY: ${{ env.IMAGE_REGISTRY }}
          IMAGE_NAME: ${{ env.IMAGE_NAME }}
        run: |
          set -x
          echo "registry=${IMAGE_REGISTRY,,}" >> $GITHUB_OUTPUT
          echo "image=${IMAGE_NAME,,}" >> $GITHUB_OUTPUT

      - name: Push To GHCR
        uses: redhat-actions/push-to-registry@5ed88d269cf581ea9ef6dd6806d01562096bee9c # v2
        if: github.event_name != 'pull_request'
        id: push
        env:
          REGISTRY_USER: ${{ github.actor }}
          REGISTRY_PASSWORD: ${{ github.token }}
        with:
          registry: ${{ steps.lowercase.outputs.registry }}
          image: ${{ steps.lowercase.outputs.image }}
          tags: ${{ steps.metadata.outputs.tags }}

      # This section is optional and only needs to be enabled if you plan on distributing
      # your project for others to consume. You will need to create a public and private key
      # using Cosign and save the private key as a repository secret in Github for this workflow
      # to consume. For more details, review the image signing section of the README.
      - name: Install Cosign
        uses: sigstore/cosign-installer@398d4b0eeef1380460a10c8013a76f728fb906ac # v3.9.1
        if: github.event_name != 'pull_request'

      - name: Sign container image
        if: github.event_name != 'pull_request'
        env:
          DIGEST: ${{ steps.push.outputs.digest }}
          REGISTRY_PATH: ${{ steps.push.outputs.registry-path }}
          COSIGN_EXPERIMENTAL: false
          COSIGN_PRIVATE_KEY: ${{ secrets.SIGNING_SECRET }}
        run: |
          # Sign using digest instead of tags to avoid warnings
          cosign sign -y --key env://COSIGN_PRIVATE_KEY ${REGISTRY_PATH}@${DIGEST}

  build_containers:
    name: Build container image (${{ matrix.variant.name }})
    runs-on: ubuntu-24.04

    strategy:
      fail-fast: false  # Allow both variants to complete even if one fails
      matrix:
        variant:
          - name: base
            image: bazzite-ai-container
            target: base-container
            description: Base development container for bazzite-ai (CPU-only)
          - name: nvidia
            image: bazzite-ai-container-nvidia
            target: nvidia-container
            description: NVIDIA/CUDA container with cuDNN and TensorRT for bazzite-ai
            # NVIDIA variant optimized: ~1.5GB (CUDA libraries only, no dev tools)

    permissions:
      contents: read
      packages: write
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

      # Monitor disk space (temporary validation that removal is safe)
      - name: Check initial disk space
        run: |
          echo "=== Disk Space Before Build ==="
          df -h
          echo "=== Available Space Summary ==="
          df -h / | awk 'NR==2 {print "Root: " $4 " available (" $5 " used)"}'

      # Persistent DNF5 cache shared across all builds
      # Uses variant-specific keys but can restore from other variants
      - name: Cache DNF5 packages
        uses: actions/cache@v4
        id: dnf-cache
        with:
          path: /tmp/dnf-cache
          key: ${{ runner.os }}-dnf5-containers-${{ matrix.variant.name }}-${{ hashFiles('Containerfile.containers', 'build_files/devcontainer/**', 'build_files/container-nvidia/**') }}
          restore-keys: |
            ${{ runner.os }}-dnf5-containers-${{ matrix.variant.name }}-
            ${{ runner.os }}-dnf5-containers-
            ${{ runner.os }}-dnf5-os-
            ${{ runner.os }}-dnf5-

      # Set up DNF cache directory for buildah to use
      - name: Set up DNF cache directory
        run: |
          sudo mkdir -p /var/cache/dnf5
          sudo chown -R $(id -u):$(id -g) /var/cache/dnf5
          # Restore from GitHub Actions cache if it exists
          if [ -d "/tmp/dnf-cache/dnf5" ]; then
            echo "Restoring DNF cache from /tmp/dnf-cache/dnf5 to /var/cache/dnf5"
            sudo cp -rp /tmp/dnf-cache/dnf5/* /var/cache/dnf5/ || true
            echo "Cache size: $(du -sh /var/cache/dnf5 | cut -f1)"
          else
            echo "No existing cache found, starting fresh"
          fi

      # Pre-pull and cache base images in parallel
      - name: Pull and cache base images
        run: |
          mkdir -p ~/.local/share/containers/storage
          # Pull Fedora base image for container builds in parallel
          buildah pull fedora:42 || true &
          # Wait for all pulls to complete
          wait
          echo "✓ Base images pulled successfully"

      - name: Get current date
        id: date
        run: echo "date=$(date -u +%Y\-%m\-%d\T%H\:%M\:%S\Z)" >> $GITHUB_OUTPUT

      - name: Image Metadata
        uses: docker/metadata-action@902fa8ec7d6ecbf8d84d538b9b233a880e428804 # v5
        id: metadata
        with:
          tags: |
            type=raw,value=latest
            type=raw,value=stable
            type=raw,value={{date 'YYYYMMDD'}}
            type=sha,enable=${{ github.event_name == 'pull_request' }}
            type=ref,event=pr
          labels: |
            org.opencontainers.image.title=${{ matrix.variant.image }}
            org.opencontainers.image.description=${{ matrix.variant.description }}
            org.opencontainers.image.created=${{ steps.date.outputs.date }}
            org.opencontainers.image.source=https://github.com/${{ github.repository_owner }}/bazzite-ai/blob/main/Containerfile.containers
            org.opencontainers.image.url=https://github.com/${{ github.repository_owner }}/bazzite-ai
            org.opencontainers.image.vendor=${{ github.repository_owner }}
          sep-tags: " "
          sep-annotations: " "

      # Unified buildah cache with hierarchical restore keys
      # Both variants share cache for common-base stage and can reuse OS build layers
      - name: Restore buildah cache tarball
        uses: actions/cache/restore@v4
        id: buildah-cache
        with:
          path: /tmp/buildah-cache-staging/buildah-cache.tar.gz
          key: ${{ runner.os }}-buildah-containers-${{ matrix.variant.name }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildah-containers-${{ matrix.variant.name }}-
            ${{ runner.os }}-buildah-containers-
            ${{ runner.os }}-buildah-os-
            ${{ runner.os }}-buildah-

      # Extract buildah cache if it was restored
      - name: Extract buildah cache
        if: steps.buildah-cache.outputs.cache-hit == 'true'
        run: |
          echo "Extracting buildah cache from tarball"
          mkdir -p ~/.local/share/containers
          sudo tar -xzf /tmp/buildah-cache-staging/buildah-cache.tar.gz -C ~/.local/share/containers 2>/dev/null || true
          sudo chown -R $(id -u):$(id -g) ~/.local/share/containers
          echo "✓ Buildah cache restored"

      - name: Build Container
        uses: redhat-actions/buildah-build@7a95fa7ee0f02d552a32753e7414641a04307056 # v2.13
        id: build
        with:
          containerfiles: ./Containerfile.containers
          image: ${{ matrix.variant.image }}
          tags: ${{ steps.metadata.outputs.tags }}
          labels: ${{ steps.metadata.outputs.labels }}
          oci: false
          # Use --target to select which variant to build
          # Mount DNF cache directory to speed up package downloads
          extra-args: |
            --target=${{ matrix.variant.target }}
            --volume /var/cache/dnf5:/var/cache/dnf5:z
          build-args: |
            FEDORA_VERSION=42

      # Save DNF cache back to GitHub Actions cache location
      - name: Save DNF cache
        if: always()
        run: |
          echo "Saving DNF cache from /var/cache/dnf5 to /tmp/dnf-cache"
          mkdir -p /tmp/dnf-cache
          sudo cp -rp /var/cache/dnf5 /tmp/dnf-cache/ || true
          echo "Cache size: $(du -sh /tmp/dnf-cache | cut -f1)"

      # Manually save buildah cache with sudo to avoid permission errors
      # The standard actions/cache fails on setuid/shadow files
      - name: Save buildah cache manually
        if: always()
        run: |
          echo "Saving buildah cache manually with sudo"
          mkdir -p /tmp/buildah-cache-staging
          sudo tar -czf /tmp/buildah-cache-staging/buildah-cache.tar.gz -C ~/.local/share/containers . 2>/dev/null || true
          sudo chown $(id -u):$(id -g) /tmp/buildah-cache-staging/buildah-cache.tar.gz
          echo "Buildah cache size: $(du -sh /tmp/buildah-cache-staging/buildah-cache.tar.gz | cut -f1)"

      # Cache the buildah tarball (avoids permission issues)
      - name: Cache buildah tarball
        uses: actions/cache/save@v4
        if: always()
        with:
          path: /tmp/buildah-cache-staging/buildah-cache.tar.gz
          key: ${{ runner.os }}-buildah-containers-${{ matrix.variant.name }}-${{ github.sha }}

      # Monitor disk space (temporary validation that removal is safe)
      - name: Check final disk space
        run: |
          echo "=== Disk Space After Build ==="
          df -h
          echo "=== Available Space Summary ==="
          df -h / | awk 'NR==2 {print "Root: " $4 " available (" $5 " used)"}'
          echo "=== Peak Usage Check ==="
          USAGE=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
          echo "Peak disk usage: ${USAGE}%"
          if [ "$USAGE" -gt 85 ]; then
            echo "::warning::Disk usage exceeded 85% - may need optimization"
          else
            echo "✓ Disk usage is acceptable (<85%)"
          fi

      - name: Login to GitHub Container Registry
        uses: docker/login-action@74a5d142397b4f367a81961eba4e8cd7edddf772 # v3
        if: github.event_name != 'pull_request'
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Lowercase Image
        id: lowercase
        run: |
          echo "registry=ghcr.io/${{ github.repository_owner }}" >> $GITHUB_OUTPUT
          echo "image=${{ matrix.variant.image }}" >> $GITHUB_OUTPUT

      - name: Push to GHCR
        uses: redhat-actions/push-to-registry@5ed88d269cf581ea9ef6dd6806d01562096bee9c # v2
        if: github.event_name != 'pull_request'
        id: push
        with:
          registry: ghcr.io/${{ github.repository_owner }}
          image: ${{ steps.lowercase.outputs.image }}
          tags: ${{ steps.metadata.outputs.tags }}

      - name: Install Cosign
        uses: sigstore/cosign-installer@398d4b0eeef1380460a10c8013a76f728fb906ac # v3.9.1
        if: github.event_name != 'pull_request'

      - name: Sign Image
        if: github.event_name != 'pull_request'
        continue-on-error: true  # Don't fail build if signing fails
        env:
          DIGEST: ${{ steps.push.outputs.digest }}
          REGISTRY_PATH: ${{ steps.push.outputs.registry-path }}
          COSIGN_EXPERIMENTAL: false
          COSIGN_PRIVATE_KEY: ${{ secrets.SIGNING_SECRET }}
        run: |
          # Sign using digest instead of tags to avoid warnings
          cosign sign -y --key env://COSIGN_PRIVATE_KEY ${REGISTRY_PATH}@${DIGEST}

  check:
    name: Check all builds successful
    if: always()
    runs-on: ubuntu-latest
    needs: [build_push, build_containers]
    steps:
      - name: Check Jobs
        env:
          JOBS: ${{ toJson(needs) }}
        run: |
          echo "Job status:"
          echo $JOBS | jq -r 'to_entries[] | " - \(.key): \(.value.result)"'

          for i in $(echo $JOBS | jq -r 'to_entries[] | .value.result'); do
            if [ "$i" != "success" ] && [ "$i" != "skipped" ]; then
              echo ""
              echo "Status check not okay!"
              exit 1
            fi
          done
